name: Production Database Backups

on:
  schedule:
    # Daily full backup at 06:00 UTC (03:00 AM Argentina)
    - cron: '0 6 * * *'
    # Monthly full backup at 08:00 UTC (05:00 AM Argentina) on 1st of month
    - cron: '0 8 1 * *'
    # Hourly incremental backup (critical tables only)
    - cron: '0 * * * *'
    # Weekly summary email on Fridays at 20:00 UTC (17:00 Argentina)
    - cron: '0 20 * * 5'
  workflow_dispatch:
    inputs:
      backup_type:
        description: 'Type of backup to run'
        required: true
        default: 'daily'
        type: choice
        options:
          - daily
          - monthly
          - hourly
          - weekly-summary

env:
  NODE_VERSION: '20'

jobs:
  backup:
    runs-on: ubuntu-24.04
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install PostgreSQL 17 client
        run: |
          sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
          wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          sudo apt-get update
          sudo apt-get install -y postgresql-client-17
          pg_dump --version

      - name: Install dependencies
        run: npm install --no-save googleapis @sendgrid/mail google-auth-library

      - name: Determine backup type
        id: backup-type
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "type=${{ github.event.inputs.backup_type }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" == "0 6 * * *" ]; then
            echo "type=daily" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" == "0 8 1 * *" ]; then
            echo "type=monthly" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" == "0 20 * * 5" ]; then
            echo "type=weekly-summary" >> $GITHUB_OUTPUT
          else
            echo "type=hourly" >> $GITHUB_OUTPUT
          fi

      - name: Create backup script
        run: |
          cat > backup.mjs << 'SCRIPT_EOF'
          import { google } from 'googleapis';
          import { exec } from 'child_process';
          import { createReadStream, statSync, unlinkSync } from 'fs';
          import { promisify } from 'util';

          const execAsync = promisify(exec);

          function sanitizeError(error) {
            let msg = error.message || String(error);
            msg = msg.replace(/postgresql:\/\/[^@]+@/gi, 'postgresql://***:***@');
            msg = msg.replace(/postgres:\/\/[^@]+@/gi, 'postgres://***:***@');
            msg = msg.replace(/password[=:][^\s&"']+/gi, 'password=***');
            return msg;
          }

          const BACKUP_TYPE = process.env.BACKUP_TYPE || 'daily';
          const DATABASE_URL = process.env.DATABASE_URL;
          const GOOGLE_CREDENTIALS = process.env.GOOGLE_SERVICE_ACCOUNT_JSON;
          const DAILY_FOLDER_ID = process.env.GOOGLE_DRIVE_FOLDER_ID_DAILY;
          const MONTHLY_FOLDER_ID = process.env.GOOGLE_DRIVE_FOLDER_ID_MONTHLY;
          const HOURLY_FOLDER_ID = process.env.GOOGLE_DRIVE_FOLDER_ID_HOURLY;
          const SENDGRID_API_KEY = process.env.SENDGRID_API_KEY;
          const NOTIFICATION_EMAIL = process.env.BACKUP_NOTIFICATION_EMAIL || 'yateshaw@gmail.com';
          const FROM_EMAIL = process.env.SENDGRID_FROM_EMAIL || 'hey@simtree.co';

          // Critical tables for hourly backup
          const CRITICAL_TABLES = ['wallets', 'wallet_transactions', 'purchased_esims'];

          // Retention limits
          const RETENTION = {
            daily: 30,    // 1 month
            monthly: 12,  // 1 year
            hourly: 48    // 2 days
          };

          async function sendEmail(subject, body) {
            if (!SENDGRID_API_KEY) {
              console.log('SendGrid not configured, skipping email');
              return;
            }
            
            try {
              const response = await fetch('https://api.sendgrid.com/v3/mail/send', {
                method: 'POST',
                headers: {
                  'Authorization': `Bearer ${SENDGRID_API_KEY}`,
                  'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                  personalizations: [{ to: [{ email: NOTIFICATION_EMAIL }] }],
                  from: { email: FROM_EMAIL },
                  subject: subject,
                  content: [{ type: 'text/html', value: body }]
                })
              });
              
              if (response.ok) {
                console.log('Email notification sent');
              } else {
                console.error('Email failed:', await response.text());
              }
            } catch (error) {
              console.error('Email error:', error.message);
            }
          }

          function getAuth() {
            const credentials = JSON.parse(GOOGLE_CREDENTIALS);
            return new google.auth.GoogleAuth({
              credentials,
              scopes: ['https://www.googleapis.com/auth/drive.file']
            });
          }

          async function uploadToGoogleDrive(filePath, fileName, folderId) {
            const auth = getAuth();
            const drive = google.drive({ version: 'v3', auth });
            
            console.log(`Uploading ${fileName} to Google Drive...`);
            
            const fileMetadata = {
              name: fileName,
              parents: [folderId]
            };
            
            const media = {
              mimeType: 'application/gzip',
              body: createReadStream(filePath)
            };
            
            const response = await drive.files.create({
              requestBody: fileMetadata,
              media: media,
              fields: 'id, name, size',
              supportsAllDrives: true
            });
            
            console.log(`Uploaded: ${response.data.id} (${response.data.size} bytes)`);
            return response.data;
          }

          async function manageRetention(folderId, maxFiles) {
            const auth = getAuth();
            const drive = google.drive({ version: 'v3', auth });
            
            const listResponse = await drive.files.list({
              q: `'${folderId}' in parents and trashed=false`,
              fields: 'files(id, name, createdTime)',
              orderBy: 'createdTime desc',
              supportsAllDrives: true,
              includeItemsFromAllDrives: true
            });
            
            const files = listResponse.data.files || [];
            console.log(`Found ${files.length} backups in folder (max: ${maxFiles})`);
            
            if (files.length > maxFiles) {
              const toDelete = files.slice(maxFiles);
              console.log(`Deleting ${toDelete.length} old backups...`);
              
              for (const file of toDelete) {
                try {
                  await drive.files.delete({ fileId: file.id, supportsAllDrives: true });
                  console.log(`Deleted: ${file.name}`);
                } catch (err) {
                  if (err.code === 404 || err.message?.includes('File not found')) {
                    console.log(`Already deleted: ${file.name}`);
                  } else {
                    throw err;
                  }
                }
              }
            }
          }

          async function getBackupStats() {
            const auth = getAuth();
            const drive = google.drive({ version: 'v3', auth });
            
            const stats = {};
            const folders = {
              daily: DAILY_FOLDER_ID,
              monthly: MONTHLY_FOLDER_ID,
              hourly: HOURLY_FOLDER_ID
            };
            
            for (const [type, folderId] of Object.entries(folders)) {
              if (!folderId) continue;
              
              const listResponse = await drive.files.list({
                q: `'${folderId}' in parents and trashed=false`,
                fields: 'files(id, name, size, createdTime)',
                orderBy: 'createdTime desc',
                supportsAllDrives: true,
                includeItemsFromAllDrives: true
              });
              
              const files = listResponse.data.files || [];
              const totalSize = files.reduce((sum, f) => sum + parseInt(f.size || 0), 0);
              
              // Count backups from last 7 days
              const weekAgo = new Date(Date.now() - 7 * 24 * 60 * 60 * 1000);
              const recentBackups = files.filter(f => new Date(f.createdTime) > weekAgo);
              
              stats[type] = {
                total: files.length,
                recentCount: recentBackups.length,
                totalSizeBytes: totalSize,
                totalSizeMB: (totalSize / 1024 / 1024).toFixed(2),
                retention: RETENTION[type]
              };
            }
            
            return stats;
          }

          async function sendWeeklySummary() {
            console.log('Generating weekly backup summary...');
            
            if (!GOOGLE_CREDENTIALS) {
              throw new Error('GOOGLE_SERVICE_ACCOUNT_JSON not configured');
            }
            
            const stats = await getBackupStats();
            
            const totalStorage = Object.values(stats).reduce((sum, s) => sum + s.totalSizeBytes, 0);
            const totalBackupsThisWeek = Object.values(stats).reduce((sum, s) => sum + s.recentCount, 0);
            
            const html = `
              <h2>üìä SimTree Weekly Backup Summary</h2>
              <p><strong>Report Date:</strong> ${new Date().toISOString()}</p>
              
              <h3>Backup Statistics (Last 7 Days)</h3>
              <table border="1" cellpadding="8" style="border-collapse: collapse;">
                <tr style="background-color: #f0f0f0;">
                  <th>Type</th>
                  <th>Backups This Week</th>
                  <th>Total Backups</th>
                  <th>Storage Used</th>
                  <th>Retention Policy</th>
                </tr>
                <tr>
                  <td>Daily</td>
                  <td>${stats.daily?.recentCount || 0}</td>
                  <td>${stats.daily?.total || 0}</td>
                  <td>${stats.daily?.totalSizeMB || 0} MB</td>
                  <td>${RETENTION.daily} backups</td>
                </tr>
                <tr>
                  <td>Monthly</td>
                  <td>${stats.monthly?.recentCount || 0}</td>
                  <td>${stats.monthly?.total || 0}</td>
                  <td>${stats.monthly?.totalSizeMB || 0} MB</td>
                  <td>${RETENTION.monthly} backups</td>
                </tr>
                <tr>
                  <td>Hourly</td>
                  <td>${stats.hourly?.recentCount || 0}</td>
                  <td>${stats.hourly?.total || 0}</td>
                  <td>${stats.hourly?.totalSizeMB || 0} MB</td>
                  <td>${RETENTION.hourly} backups</td>
                </tr>
              </table>
              
              <h3>Summary</h3>
              <ul>
                <li><strong>Total backups this week:</strong> ${totalBackupsThisWeek}</li>
                <li><strong>Total storage used:</strong> ${(totalStorage / 1024 / 1024).toFixed(2)} MB</li>
                <li><strong>System status:</strong> ‚úÖ Operational</li>
              </ul>
              
              <p style="color: #666; font-size: 12px;">
                This is an automated report from SimTree Backup System running on GitHub Actions.
              </p>
            `;
            
            await sendEmail('üìä SimTree Weekly Backup Summary', html);
            console.log('‚úÖ Weekly summary sent');
            return { success: true, type: 'weekly-summary' };
          }

          async function runBackupWithRetry(maxAttempts = 3) {
            let lastError;
            
            for (let attempt = 1; attempt <= maxAttempts; attempt++) {
              try {
                console.log(`Attempt ${attempt}/${maxAttempts}...`);
                return await runBackup();
              } catch (error) {
                lastError = error;
                console.error(`Attempt ${attempt} failed:`, sanitizeError(error));
                
                if (attempt < maxAttempts) {
                  const delay = Math.pow(2, attempt - 1) * 1000;
                  console.log(`Waiting ${delay}ms before retry...`);
                  await new Promise(r => setTimeout(r, delay));
                }
              }
            }
            
            throw lastError;
          }

          async function runBackup() {
            console.log(`Starting ${BACKUP_TYPE} backup...`);
            
            if (!DATABASE_URL) {
              throw new Error('DATABASE_URL not configured');
            }
            
            if (!GOOGLE_CREDENTIALS) {
              throw new Error('GOOGLE_SERVICE_ACCOUNT_JSON not configured');
            }
            
            // Determine folder and retention based on backup type
            let folderId, maxRetention, filePrefix;
            
            switch (BACKUP_TYPE) {
              case 'monthly':
                folderId = MONTHLY_FOLDER_ID;
                maxRetention = RETENTION.monthly;
                filePrefix = 'simtree-monthly-backup';
                break;
              case 'hourly':
                folderId = HOURLY_FOLDER_ID;
                maxRetention = RETENTION.hourly;
                filePrefix = 'simtree-hourly-backup';
                break;
              default: // daily
                folderId = DAILY_FOLDER_ID;
                maxRetention = RETENTION.daily;
                filePrefix = 'simtree-daily-backup';
            }
            
            if (!folderId) {
              throw new Error(`Folder ID not configured for ${BACKUP_TYPE} backup`);
            }
            
            const now = new Date();
            const timestamp = now.toISOString()
              .replace(/[-:T]/g, '')
              .slice(0, 14)
              .replace(/(\d{8})(\d{6})/, '$1-$2');
            const fileName = `${filePrefix}-${timestamp}.sql.gz`;
            const filePath = `/tmp/${fileName}`;
            
            // Build pg_dump command with error handling
            let pgDumpCmd = `pg_dump "${DATABASE_URL}" --no-owner --no-acl`;
            
            if (BACKUP_TYPE === 'hourly') {
              const tableArgs = CRITICAL_TABLES.map(t => `-t ${t}`).join(' ');
              pgDumpCmd = `pg_dump "${DATABASE_URL}" --no-owner --no-acl ${tableArgs}`;
            }
            
            // Use bash pipefail to catch pg_dump errors
            const fullCmd = `bash -c 'set -o pipefail; ${pgDumpCmd} 2>&1 | gzip -9 > ${filePath}'`;
            
            console.log(`Running pg_dump for ${BACKUP_TYPE} backup...`);
            
            try {
              const { stdout, stderr } = await execAsync(fullCmd);
              if (stderr) console.log('pg_dump output:', stderr);
            } catch (dumpError) {
              // Read the partial file to see the error
              const { readFileSync } = await import('fs');
              const { gunzipSync } = await import('zlib');
              try {
                const content = gunzipSync(readFileSync(filePath)).toString().slice(0, 500);
                console.error('pg_dump failed. Output:', content);
              } catch (e) {
                console.error('pg_dump failed:', sanitizeError(dumpError));
              }
              throw new Error(`pg_dump failed: ${sanitizeError(dumpError)}`);
            }
            
            const stats = statSync(filePath);
            console.log(`Backup created: ${fileName} (${(stats.size / 1024 / 1024).toFixed(2)} MB)`);
            
            // Validate backup size (minimum 100 bytes for a valid dump)
            if (stats.size < 100) {
              throw new Error(`Backup file too small (${stats.size} bytes). Database connection may have failed.`);
            }
            
            // Upload to Google Drive
            const uploadResult = await uploadToGoogleDrive(filePath, fileName, folderId);
            
            // Cleanup local file
            unlinkSync(filePath);
            
            // Manage retention
            await manageRetention(folderId, maxRetention);
            
            console.log('‚úÖ Backup completed successfully');
            return { success: true, fileName, size: stats.size, driveFileId: uploadResult.id };
          }

          async function main() {
            try {
              if (BACKUP_TYPE === 'weekly-summary') {
                return await sendWeeklySummary();
              }
              
              const result = await runBackupWithRetry(3);
              console.log('Backup result:', JSON.stringify(result, null, 2));
              process.exit(0);
            } catch (error) {
              const safeError = sanitizeError(error);
              console.error('‚ùå Backup failed after all retries:', safeError);
              
              // Send failure notification
              await sendEmail(
                `‚ùå ${BACKUP_TYPE.toUpperCase()} Backup Failed - SimTree`,
                `
                  <h2>‚ö†Ô∏è Database Backup Failed</h2>
                  <p><strong>Type:</strong> ${BACKUP_TYPE}</p>
                  <p><strong>Attempts:</strong> 3</p>
                  <p><strong>Error:</strong> ${safeError}</p>
                  <p><strong>Time:</strong> ${new Date().toISOString()}</p>
                  <h3>Recommended Actions:</h3>
                  <ul>
                    <li>Check database connectivity</li>
                    <li>Verify Google Drive credentials</li>
                    <li>Review GitHub Actions logs</li>
                  </ul>
                `
              );
              
              process.exit(1);
            }
          }

          main();
          SCRIPT_EOF

      - name: Run backup
        env:
          BACKUP_TYPE: ${{ steps.backup-type.outputs.type }}
          DATABASE_URL: ${{ secrets.PROD_DATABASE_URL }}
          GOOGLE_SERVICE_ACCOUNT_JSON: ${{ secrets.GOOGLE_SERVICE_ACCOUNT_JSON }}
          GOOGLE_DRIVE_FOLDER_ID_DAILY: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID_DAILY }}
          GOOGLE_DRIVE_FOLDER_ID_MONTHLY: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID_MONTHLY }}
          GOOGLE_DRIVE_FOLDER_ID_HOURLY: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID_HOURLY }}
          SENDGRID_API_KEY: ${{ secrets.SENDGRID_API_KEY }}
          SENDGRID_FROM_EMAIL: ${{ secrets.SENDGRID_FROM_EMAIL }}
          BACKUP_NOTIFICATION_EMAIL: ${{ secrets.BACKUP_NOTIFICATION_EMAIL }}
        run: node backup.mjs
