name: Production Database Backups
on:
  schedule:
    - cron: '0 6 * * *'
    - cron: '0 8 1 * *'
    - cron: '0 * * * *'
    - cron: '0 20 * * 5'
  workflow_dispatch:
    inputs:
      backup_type:
        description: 'Tipo de backup'
        required: true
        default: 'daily'
        type: choice
        options: [daily, monthly, hourly, weekly-summary]

env:
  NODE_VERSION: '20'

jobs:
  backup:
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      - name: Install PostgreSQL 17 client
        run: |
          sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
          wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          sudo apt-get update
          sudo apt-get install -y postgresql-client-17
          echo "/usr/lib/postgresql/17/bin" >> $GITHUB_PATH
      - name: Install dependencies
        run: npm install --no-save googleapis @sendgrid/mail google-auth-library
      - name: Determine backup type
        id: backup-type
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "type=${{ github.event.inputs.backup_type }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" == "0 20 * * 5" ]; then
            echo "type=weekly-summary" >> $GITHUB_OUTPUT
          else
            echo "type=daily" >> $GITHUB_OUTPUT
          fi

      - name: Create and Run Backup Script
        env:
          BACKUP_TYPE: ${{ steps.backup-type.outputs.type }}
          DATABASE_URL: ${{ secrets.PROD_DATABASE_URL }}
          GOOGLE_SERVICE_ACCOUNT_JSON: ${{ secrets.GOOGLE_SERVICE_ACCOUNT_JSON }}
          GOOGLE_DRIVE_FOLDER_ID_DAILY: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID_DAILY }}
          GOOGLE_DRIVE_FOLDER_ID_MONTHLY: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID_MONTHLY }}
          GOOGLE_DRIVE_FOLDER_ID_HOURLY: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID_HOURLY }}
          SENDGRID_API_KEY: ${{ secrets.SENDGRID_API_KEY }}
          FROM_EMAIL: ${{ secrets.SENDGRID_FROM_EMAIL }}
          NOTIFICATION_EMAIL: ${{ secrets.BACKUP_NOTIFICATION_EMAIL }}
        run: |
          cat > backup.mjs << 'EOF'
          import { google } from 'googleapis';
          import { exec } from 'child_process';
          import { createReadStream, unlinkSync, existsSync } from 'fs';
          import { promisify } from 'util';
          const execAsync = promisify(exec);

          const { BACKUP_TYPE, DATABASE_URL, GOOGLE_SERVICE_ACCOUNT_JSON, GOOGLE_DRIVE_FOLDER_ID_DAILY, GOOGLE_DRIVE_FOLDER_ID_MONTHLY, GOOGLE_DRIVE_FOLDER_ID_HOURLY, SENDGRID_API_KEY, NOTIFICATION_EMAIL, FROM_EMAIL } = process.env;
          const RETENTION = { daily: 30, monthly: 12, hourly: 48 };

          function getAuth() {
            return new google.auth.GoogleAuth({
              credentials: JSON.parse(GOOGLE_SERVICE_ACCOUNT_JSON),
              scopes: ['https://www.googleapis.com/auth/drive']
            });
          }

          async function sendEmail(subject, html) {
            try {
              await fetch('https://api.sendgrid.com/v3/mail/send', {
                method: 'POST',
                headers: { 'Authorization': `Bearer ${SENDGRID_API_KEY}`, 'Content-Type': 'application/json' },
                body: JSON.stringify({
                  personalizations: [{ to: [{ email: NOTIFICATION_EMAIL }] }],
                  from: { email: FROM_EMAIL, name: 'SimTree Backup' },
                  subject,
                  content: [{ type: 'text/html', value: html }]
                })
              });
            } catch (e) { console.error("Email error:", e.message); }
          }

          async function run() {
            const drive = google.drive({ version: 'v3', auth: getAuth() });

            if (BACKUP_TYPE === 'weekly-summary') {
              let rows = "";
              const weekAgo = new Date(); weekAgo.setDate(weekAgo.getDate() - 7);
              const folders = [
                { name: 'Daily', id: GOOGLE_DRIVE_FOLDER_ID_DAILY, pol: '30' },
                { name: 'Monthly', id: GOOGLE_DRIVE_FOLDER_ID_MONTHLY, pol: '12' },
                { name: 'Hourly', id: GOOGLE_DRIVE_FOLDER_ID_HOURLY, pol: '48' }
              ];
              for (const f of folders) {
                const res = await drive.files.list({ q: `'${f.id}' in parents and trashed=false`, fields: 'files(id, size, createdTime)', pageSize: 1000, supportsAllDrives: true, includeItemsFromAllDrives: true });
                const files = res.data.files || [];
                const thisWeek = files.filter(x => new Date(x.createdTime) > weekAgo).length;
                const size = (files.reduce((a, b) => a + parseInt(b.size || 0), 0) / (1024*1024)).toFixed(2);
                rows += `<tr><td style="padding:8px;border:1px solid #444">${f.name}</td><td style="padding:8px;border:1px solid #444">${thisWeek}</td><td style="padding:8px;border:1px solid #444">${files.length}</td><td style="padding:8px;border:1px solid #444">${size} MB</td><td style="padding:8px;border:1px solid #444">${f.pol}</td></tr>`;
              }
              await sendEmail("ðŸ“Š SimTree Backup Summary", `<div style="font-family:sans-serif;background:#1a1a1a;color:#fff;padding:20px"><h2>ðŸ“Š Summary</h2><table style="width:100%;border-collapse:collapse;background:#2d2d2d"><thead><tr style="background:#444"><th>Type</th><th>Week</th><th>Total</th><th>Size</th><th>Policy</th></tr></thead><tbody>${rows}</tbody></table></div>`);
              return;
            }

            const folderId = BACKUP_TYPE === 'hourly' ? GOOGLE_DRIVE_FOLDER_ID_HOURLY : (BACKUP_TYPE === 'monthly' ? GOOGLE_DRIVE_FOLDER_ID_MONTHLY : GOOGLE_DRIVE_FOLDER_ID_DAILY);
            const fileName = `simtree-${BACKUP_TYPE}-${new Date().getTime()}.sql.gz`;
            const filePath = `/tmp/${fileName}`;
            
            console.log(`>>> Iniciando Backup: ${BACKUP_TYPE}`);
            let cmd = `/usr/lib/postgresql/17/bin/pg_dump "${DATABASE_URL}" --no-owner --no-acl`;
            if (BACKUP_TYPE === 'hourly') cmd += ` -t wallets -t wallet_transactions -t purchased_esims`;
            await execAsync(`${cmd} | gzip -9 > ${filePath}`);
            
            await drive.files.create({ requestBody: { name: fileName, parents: [folderId] }, media: { mimeType: 'application/gzip', body: createReadStream(filePath) }, supportsAllDrives: true });

            console.log(">>> Analizando limpieza...");
            const res = await drive.files.list({ q: `'${folderId}' in parents and trashed=false`, orderBy: 'createdTime asc', pageSize: 1000, fields: 'files(id, name)', supportsAllDrives: true, includeItemsFromAllDrives: true });
            const files = res.data.files || [];
            
            if (files.length > RETENTION[BACKUP_TYPE]) {
              const toDelete = files.slice(0, files.length - RETENTION[BACKUP_TYPE]);
              console.log(`>>> Se encontraron ${files.length} archivos. Borrando ${toDelete.length}...`);
              
              let deleted = 0;
              for (const file of toDelete) {
                try {
                  await drive.files.delete({ fileId: file.id, supportsAllDrives: true });
                  deleted++;
                  if (deleted % 25 === 0) console.log(`>>> Progreso: ${deleted}/${toDelete.length} borrados...`);
                } catch (e) {
                  if (e.code !== 404) console.error(`Error en ${file.name}: ${e.message}`);
                }
              }
              console.log(`>>> Limpieza terminada. Se borraron ${deleted} archivos.`);
            }

            if (existsSync(filePath)) unlinkSync(filePath);
            console.log(">>> âœ… Proceso completo.");
          }
          run().catch(e => { console.error(e); process.exit(1); });
          EOF
          node backup.mjs
