name: Production Database Backups
on:
  schedule:
    - cron: '0 6 * * *'
    - cron: '0 8 1 * *'
    - cron: '0 * * * *'
    - cron: '0 20 * * 5'
  workflow_dispatch:
    inputs:
      backup_type:
        description: 'Tipo de backup'
        required: true
        default: 'daily'
        type: choice
        options: [daily, monthly, hourly, weekly-summary]

env:
  NODE_VERSION: '20'

jobs:
  backup:
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      - name: Install PostgreSQL 17 client
        run: |
          sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
          wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          sudo apt-get update
          sudo apt-get install -y postgresql-client-17
          echo "/usr/lib/postgresql/17/bin" >> $GITHUB_PATH
      - name: Install dependencies
        run: npm install --no-save googleapis @sendgrid/mail google-auth-library
      - name: Create and Run Backup Script
        env:
          BACKUP_TYPE: ${{ github.event.inputs.backup_type || 'hourly' }}
          DATABASE_URL: ${{ secrets.PROD_DATABASE_URL }}
          GOOGLE_SERVICE_ACCOUNT_JSON: ${{ secrets.GOOGLE_SERVICE_ACCOUNT_JSON }}
          GOOGLE_DRIVE_FOLDER_ID_DAILY: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID_DAILY }}
          GOOGLE_DRIVE_FOLDER_ID_MONTHLY: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID_MONTHLY }}
          GOOGLE_DRIVE_FOLDER_ID_HOURLY: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID_HOURLY }}
          SENDGRID_API_KEY: ${{ secrets.SENDGRID_API_KEY }}
          FROM_EMAIL: ${{ secrets.SENDGRID_FROM_EMAIL }}
          NOTIFICATION_EMAIL: ${{ secrets.BACKUP_NOTIFICATION_EMAIL }}
        run: |
          cat > backup.mjs << 'EOF'
          import { google } from 'googleapis';
          import { exec } from 'child_process';
          import { createReadStream, unlinkSync, existsSync } from 'fs';
          import { promisify } from 'util';
          import sgMail from '@sendgrid/mail';
          const execAsync = promisify(exec);

          const { 
            BACKUP_TYPE, DATABASE_URL, GOOGLE_SERVICE_ACCOUNT_JSON, 
            GOOGLE_DRIVE_FOLDER_ID_DAILY, GOOGLE_DRIVE_FOLDER_ID_MONTHLY, 
            GOOGLE_DRIVE_FOLDER_ID_HOURLY, SENDGRID_API_KEY, 
            FROM_EMAIL, NOTIFICATION_EMAIL 
          } = process.env;

          const RETENTION = { daily: 30, monthly: 12, hourly: 48 };

          sgMail.setApiKey(SENDGRID_API_KEY);

          const auth = new google.auth.GoogleAuth({
            credentials: JSON.parse(GOOGLE_SERVICE_ACCOUNT_JSON),
            scopes: ['https://www.googleapis.com/auth/drive']
          });
          const drive = google.drive({ version: 'v3', auth });

          async function sendSummary(content) {
            console.log(">>> Enviando Reporte Semanal por Email...");
            const msg = {
              to: NOTIFICATION_EMAIL,
              from: FROM_EMAIL,
              subject: `Simtree DB: Weekly Backup Summary`,
              text: content,
              html: `<pre style="font-family: monospace;">${content}</pre>`
            };
            await sgMail.send(msg);
            console.log(">>> Email enviado exitosamente.");
          }

          async function run() {
            // Si es un resumen semanal, no hacemos dump, solo listamos y enviamos mail
            if (BACKUP_TYPE === 'weekly-summary') {
              let report = "RESUMEN SEMANAL DE BACKUPS EN DRIVE\n";
              report += "====================================\n\n";
              
              const folders = [
                { name: 'HOURLY', id: GOOGLE_DRIVE_FOLDER_ID_HOURLY },
                { name: 'DAILY', id: GOOGLE_DRIVE_FOLDER_ID_DAILY },
                { name: 'MONTHLY', id: GOOGLE_DRIVE_FOLDER_ID_MONTHLY }
              ];

              for (const f of folders) {
                const res = await drive.files.list({
                  q: `'${f.id}' in parents and trashed=false`,
                  fields: 'files(name, size, createdTime)',
                  orderBy: 'createdTime desc',
                  supportsAllDrives: true,
                  includeItemsFromAllDrives: true
                });
                const files = res.data.files || [];
                report += `üìÅ ${f.name}:\n`;
                report += `- Total archivos: ${files.length}\n`;
                if (files.length > 0) {
                  report += `- √öltimo: ${files[0].name} (${(files[0].size / 1024 / 1024).toFixed(2)} MB)\n`;
                  report += `- Fecha: ${files[0].createdTime}\n`;
                }
                report += "\n";
              }
              
              await sendSummary(report);
              return;
            }

            // --- L√≥gica Normal de Backup ---
            const folderId = BACKUP_TYPE === 'hourly' ? GOOGLE_DRIVE_FOLDER_ID_HOURLY : (BACKUP_TYPE === 'monthly' ? GOOGLE_DRIVE_FOLDER_ID_MONTHLY : GOOGLE_DRIVE_FOLDER_ID_DAILY);
            const fileName = `simtree-${BACKUP_TYPE}-backup-${new Date().toISOString().replace(/[:.]/g, '-')}.sql.gz`;
            const filePath = `/tmp/${fileName}`;
            
            console.log(`>>> Iniciando Backup: ${BACKUP_TYPE}`);
            let cmd = `/usr/lib/postgresql/17/bin/pg_dump "${DATABASE_URL}" --no-owner --no-acl`;
            if (BACKUP_TYPE === 'hourly') cmd += ` -t wallets -t wallet_transactions -t purchased_esims`;
            await execAsync(`${cmd} | gzip -9 > ${filePath}`);
            
            await drive.files.create({ 
              requestBody: { name: fileName, parents: [folderId] }, 
              media: { mimeType: 'application/gzip', body: createReadStream(filePath) }, 
              supportsAllDrives: true 
            });

            console.log(">>> Iniciando limpieza profunda...");
            let continueCleaning = true;
            let totalDeleted = 0;

            while (continueCleaning) {
              const listRes = await drive.files.list({ 
                q: `'${folderId}' in parents and trashed=false`, 
                orderBy: 'createdTime asc', 
                pageSize: 100, 
                fields: 'files(id, name)', 
                supportsAllDrives: true, 
                includeItemsFromAllDrives: true 
              });

              let files = listRes.data.files || [];
              const limit = RETENTION[BACKUP_TYPE];

              if (files.length > limit) {
                const toDelete = files.slice(0, files.length - limit);
                console.log(`>>> Detectados ${files.length} archivos. Moviendo a papelera ${toDelete.length}...`);
                
                for (const file of toDelete) {
                  try {
                    await drive.files.update({ 
                      fileId: file.id, 
                      requestBody: { trashed: true },
                      supportsAllDrives: true 
                    });
                    totalDeleted++;
                  } catch (e) {
                    if (e.code === 404) continue;
                    console.error(`>>> Error en ${file.name}: ${e.message}`);
                  }
                }
                await new Promise(r => setTimeout(r, 2000));
              } else {
                continueCleaning = false;
              }
            }

            console.log(`>>> Limpieza finalizada. Quedan ${(limit || 'N/A')} archivos.`);
            if (existsSync(filePath)) unlinkSync(filePath);
            console.log(">>> ‚úÖ Proceso terminado.");
          }

          run().catch(e => { 
            console.error(">>> ERROR CR√çTICO:", e);
            process.exit(1); 
          });
          EOF
          node backup.mjs
