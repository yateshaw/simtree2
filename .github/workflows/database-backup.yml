name: Production Database Backups
on:
  schedule:
    - cron: '0 6 * * *'     # Diarios 06:00 UTC
    - cron: '0 8 1 * *'     # Mensuales el d√≠a 1
    - cron: '0 * * * *'     # Por hora
    - cron: '0 20 * * 5'    # Resumen semanal viernes
  workflow_dispatch:
    inputs:
      backup_type:
        description: 'Tipo de backup'
        required: true
        default: 'daily'
        type: choice
        options: [daily, monthly, hourly]

env:
  NODE_VERSION: '20'

jobs:
  backup:
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install PostgreSQL 17 client
        run: |
          sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
          wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          sudo apt-get update
          sudo apt-get install -y postgresql-client-17
          echo "/usr/lib/postgresql/17/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: npm install --no-save googleapis @sendgrid/mail google-auth-library

      - name: Determine backup type
        id: backup-type
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "type=${{ github.event.inputs.backup_type }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" == "0 6 * * *" ]; then
            echo "type=daily" >> $GITHUB_OUTPUT
          elif [ "${{ github.event.schedule }}" == "0 8 1 * *" ]; then
            echo "type=monthly" >> $GITHUB_OUTPUT
          else
            echo "type=hourly" >> $GITHUB_OUTPUT
          fi

      - name: Create and Run Backup Script
        env:
          BACKUP_TYPE: ${{ steps.backup-type.outputs.type }}
          DATABASE_URL: ${{ secrets.PROD_DATABASE_URL }}
          GOOGLE_SERVICE_ACCOUNT_JSON: ${{ secrets.GOOGLE_SERVICE_ACCOUNT_JSON }}
          GOOGLE_DRIVE_FOLDER_ID_DAILY: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID_DAILY }}
          GOOGLE_DRIVE_FOLDER_ID_MONTHLY: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID_MONTHLY }}
          GOOGLE_DRIVE_FOLDER_ID_HOURLY: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID_HOURLY }}
          SENDGRID_API_KEY: ${{ secrets.SENDGRID_API_KEY }}
          SENDGRID_FROM_EMAIL: ${{ secrets.SENDGRID_FROM_EMAIL }}
          BACKUP_NOTIFICATION_EMAIL: ${{ secrets.BACKUP_NOTIFICATION_EMAIL }}
        run: |
          cat > backup.mjs << 'EOF'
          import { google } from 'googleapis';
          import { exec } from 'child_process';
          import { createReadStream, statSync, unlinkSync, existsSync } from 'fs';
          import { promisify } from 'util';
          const execAsync = promisify(exec);

          const { BACKUP_TYPE, DATABASE_URL, GOOGLE_SERVICE_ACCOUNT_JSON, GOOGLE_DRIVE_FOLDER_ID_DAILY, GOOGLE_DRIVE_FOLDER_ID_MONTHLY, GOOGLE_DRIVE_FOLDER_ID_HOURLY } = process.env;
          const RETENTION = { daily: 30, monthly: 12, hourly: 48 };

          function getAuth() {
            return new google.auth.GoogleAuth({
              credentials: JSON.parse(GOOGLE_SERVICE_ACCOUNT_JSON),
              scopes: ['https://www.googleapis.com/auth/drive']
            });
          }

          async function uploadFile(filePath, fileName, folderId) {
            const drive = google.drive({ version: 'v3', auth: getAuth() });
            const res = await drive.files.create({
              requestBody: { name: fileName, parents: [folderId] },
              media: { mimeType: 'application/gzip', body: createReadStream(filePath) },
              supportsAllDrives: true
            });
            console.log(`‚úÖ Archivo subido con ID: ${res.data.id}`);
          }

          async function manageRetention(folderId, max) {
            const drive = google.drive({ version: 'v3', auth: getAuth() });
            const res = await drive.files.list({
              q: `'${folderId}' in parents and trashed=false`,
              fields: 'files(id, name)',
              orderBy: 'createdTime asc',
              supportsAllDrives: true,
              includeItemsFromAllDrives: true
            });
            const files = res.data.files || [];
            console.log(`Archivos en carpeta: ${files.length} (M√°ximo permitido: ${max})`);
            
            if (files.length > max) {
              const toDelete = files.slice(0, files.length - max);
              for (const file of toDelete) {
                try {
                  console.log(`Eliminando backup antiguo: ${file.name}`);
                  await drive.files.delete({ fileId: file.id, supportsAllDrives: true });
                } catch (err) {
                  if (err.code === 404) {
                    console.log(`El archivo ${file.name} ya no existe en Drive, saltando...`);
                  } else {
                    console.error(`No se pudo eliminar ${file.name}: ${err.message}`);
                  }
                }
              }
            }
          }

          async function run() {
            let folderId;
            if (BACKUP_TYPE === 'hourly') folderId = GOOGLE_DRIVE_FOLDER_ID_HOURLY;
            else if (BACKUP_TYPE === 'monthly') folderId = GOOGLE_DRIVE_FOLDER_ID_MONTHLY;
            else folderId = GOOGLE_DRIVE_FOLDER_ID_DAILY;

            const timestamp = new Date().toISOString().replace(/[-:T]/g, '').slice(0, 14);
            const fileName = `simtree-${BACKUP_TYPE}-${timestamp}.sql.gz`;
            const filePath = `/tmp/${fileName}`;
            
            console.log(`Iniciando backup tipo [${BACKUP_TYPE}]...`);
            let cmd = `/usr/lib/postgresql/17/bin/pg_dump "${DATABASE_URL}" --no-owner --no-acl`;
            if (BACKUP_TYPE === 'hourly') {
              cmd += ` -t wallets -t wallet_transactions -t purchased_esims`;
            }
            
            await execAsync(`${cmd} | gzip -9 > ${filePath}`);
            
            const stats = statSync(filePath);
            console.log(`Backup creado localmente: ${fileName} (${(stats.size / 1024).toFixed(2)} KB)`);

            await uploadFile(filePath, fileName, folderId);
            await manageRetention(folderId, RETENTION[BACKUP_TYPE]);
            
            if (existsSync(filePath)) unlinkSync(filePath);
            console.log("üöÄ Proceso completado exitosamente.");
          }

          run().catch(err => {
            console.error("‚ùå ERROR CR√çTICO:");
            console.error(err);
            process.exit(1);
          });
          EOF
          
          node backup.mjs
